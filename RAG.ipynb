{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import logging\n",
    "from pgvector.psycopg2 import register_vector\n",
    "import psycopg2\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "from tenacity import retry, wait_exponential, retry_if_exception_type, before_sleep_log, stop_after_attempt\n",
    "import os\n",
    "from prompts import *\n",
    "\n",
    "# Configure the logger with the custom format\n",
    "log_format = '%(asctime)s %(levelname)s: \\n%(message)s\\n'\n",
    "\n",
    "logging.basicConfig(filename=\"/Users/juanreyesgarcia/Dev/Python/RAG/logging.log\",\n",
    "\tlevel=logging.INFO,\n",
    "\tformat=log_format)\n",
    "\n",
    "load_dotenv(\".env\")\n",
    "LOCAL_POSTGRE_URL = os.environ.get(\"LOCAL_POSTGRE_URL\")\n",
    "OPENAI_API_KEY = os.environ.get(\"OPENAI_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import voyageai\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import tiktoken\n",
    "import pandas as pd\n",
    "\n",
    "load_dotenv(\".env\")\n",
    "\n",
    "VOYAGE_API_KEY = os.environ.get(\"VOYAGE_API_KEY\")\n",
    "\n",
    "vo = voyageai.Client(api_key=VOYAGE_API_KEY)\n",
    "\n",
    "def individual_voyage_query_embedding(query):\n",
    "    result = vo.embed(query, model=\"voyage-2\", input_type=\"query\", truncation=True)\n",
    "    embedding = np.array(result.embeddings)\n",
    "    return embedding\n",
    "\n",
    "def multiple_voyage_query_embedding(query):\n",
    "    result = vo.embed(query, model=\"voyage-2\", input_type=\"query\", truncation=True)\n",
    "    embedding = np.array(result.embeddings)\n",
    "    return embedding\n",
    "\n",
    "def num_tokens(text: str, model: str =\"gpt-3.5-turbo-1106\") -> int:\n",
    "\t#Return the number of tokens in a string.\n",
    "\tencoding = tiktoken.encoding_for_model(model)\n",
    "\treturn len(encoding.encode(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.WARNING)\n",
    "\n",
    "@retry(stop=stop_after_attempt(7), wait=wait_exponential(multiplier=1, min=2, max=10), retry=retry_if_exception_type(Exception), before_sleep=before_sleep_log(logger, logging.WARNING))\n",
    "def FinanceExpert(\n",
    "\tformatted_extracts: str,\n",
    "\tquery: str,\n",
    ") -> pd.DataFrame:\n",
    "\t\n",
    "\t\n",
    "\tlogging.info(f\"\"\"\\nCALLING: \"gpt-4-1106-preview\" \"\"\")\n",
    "\n",
    "\tclient = OpenAI(\n",
    "\t\tapi_key=OPENAI_API_KEY,\n",
    "\t)\n",
    "\n",
    "\n",
    "\tresponse = client.chat.completions.create(\n",
    "\t\tmessages = [\n",
    "\t\t\t{\"role\": \"system\", \"content\": finance_expert},\n",
    "\t\t\t{\"role\": \"user\", \"content\": f\"****{query}****\\n####{formatted_extracts}####\"}\n",
    "\t\t],\n",
    "\t\t\n",
    "\t\tmodel=\"gpt-4-1106-preview\",\n",
    "\t\ttemperature=0,\n",
    "\t)\n",
    "\t\n",
    "\tresponse_message = response.choices[0].message.content\n",
    "\n",
    "\tlogging.info(f\"gpt_4_response:\\n\\n{response_message}\")\n",
    "\n",
    "\treturn response_message\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@retry(stop=stop_after_attempt(7), wait=wait_exponential(multiplier=1, min=2, max=10), retry=retry_if_exception_type(Exception), before_sleep=before_sleep_log(logger, logging.WARNING))\n",
    "def MultipleAnswers(query:str\n",
    ") -> str:\n",
    "\t\n",
    "\t\n",
    "\tlogging.info(f\"\"\"\\nCALLING: \"gpt-4-1106-preview\" \"\"\")\n",
    "\n",
    "\tclient = OpenAI(\n",
    "\t\tapi_key=OPENAI_API_KEY,\n",
    "\t)\n",
    "\n",
    "\n",
    "\tresponse = client.chat.completions.create(\n",
    "\t\tmessages = [\n",
    "\t\t\t{\"role\": \"system\", \"content\": multiple_answers},\n",
    "\t\t\t{\"role\": \"user\", \"content\": f\"****{query}****\\n####{doc}####\"}\n",
    "\t\t],\n",
    "\t\t\n",
    "\t\tmodel=\"gpt-4-1106-preview\",\n",
    "\t\ttemperature=0,\n",
    "\t)\n",
    "\t\n",
    "\tresponse_message = response.choices[0].message.content\n",
    "\n",
    "\tlogging.info(f\"gpt_4_response:\\n\\n{response_message}\")\n",
    "\n",
    "\treturn response_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make connection and enable pgvector\n",
    "conn = psycopg2.connect(LOCAL_POSTGRE_URL)\n",
    "cursor = conn.cursor()\n",
    "cursor.execute('CREATE EXTENSION IF NOT EXISTS vector')\n",
    "register_vector(conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_keywords(df: pd.DataFrame, parameters: list) -> pd.DataFrame:\n",
    "\tregex_pattern = r'\\b(?:' + '|'.join(parameters) + r')\\b'\n",
    "\n",
    "\t# Filter the DataFrame to only include rows with standalone words\n",
    "\tdf_filtered = df[df['chunks'].str.contains(regex_pattern, case=False, regex=True, na=False)]\n",
    "\n",
    "\treturn df_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def FetchTopN(\n",
    "\t\tquery_embedding: str,\n",
    "\t\tcursor=cursor,\n",
    "\t\tsimilarity_or_distance_metric: str = \"NN\",\n",
    "\t\ttable_name: str =\"voyageai\",\n",
    "\t) -> pd.DataFrame:\n",
    "\n",
    "\t\"\"\"\n",
    "\tThis function performs these actions:\n",
    "\n",
    "\t1. Filters user's country\n",
    "\t2. Performs similarity search depending on metric\n",
    "\n",
    "\tReturns a df containing the matching id and respective chunks\n",
    "\t\"\"\"\n",
    "\t\n",
    "\tmetric_mapping = {\n",
    "\t\t\"NN\": \"<->\",\n",
    "\t\t\"inner_product\": \"<#>\",\n",
    "\t\t\"cosine\": \"<=>\"\n",
    "\t}\n",
    "\n",
    "\t# Check if the provided value exists in the dictionary\n",
    "\tif similarity_or_distance_metric in metric_mapping:\n",
    "\t\tsimilarity_metric = metric_mapping[similarity_or_distance_metric]\n",
    "\telse:\n",
    "\t\tlogging.error(\"\"\"Invalid similarity_or_distance_metric. Choose \"NN\", \"inner_product\" or \"cosine\" \"\"\")\n",
    "\t\traise Exception(\"\"\"Invalid similarity_or_distance_metric. Choose \"NN\", \"inner_product\" or \"cosine\" \"\"\")\n",
    "\n",
    "\tquery = f\"\"\"\n",
    "\tSELECT id, chunks\n",
    "\tFROM {table_name}\n",
    "\tORDER BY embeddings {similarity_metric} %s\n",
    "\tLIMIT 10;\n",
    "\t\"\"\"\n",
    "\tcursor.execute(query.format(table_name=\"voyageai\"), query_embedding)\n",
    "\n",
    "\t# Fetch all the rows\n",
    "\trows = cursor.fetchall()\n",
    "\n",
    "\t# Separate the columns into individual lists\n",
    "\tids = [row[0] for row in rows]\n",
    "\tchunks = [row[1] for row in rows]\n",
    "\n",
    "\tdf = pd.DataFrame({'id': ids, 'chunks': chunks})\n",
    "\n",
    "\treturn df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def FormatTopN(\n",
    "\tdf: pd.DataFrame,\n",
    ") -> str:\n",
    "\n",
    "\tids = df['id'].tolist()\n",
    "\tchunks = df[\"chunks\"].to_list()\n",
    "\n",
    "\ttoken_budget = 128000\n",
    "\n",
    "\t#Basically giving the most relevant IDs from the previous function\n",
    "\tmessage = \"The following are the extracts with their respective IDs from the Earnings Conference Call 2024 that you have to use to answer the user's query:\"\n",
    "\n",
    "\tfor id, chunk in zip(ids, chunks):\n",
    "\n",
    "\t\tnext_id = f'\\n<Reference ID:{id}>\\n---Extract: {chunk}---\\n'\n",
    "\t\tif (\n",
    "\t\t\tnum_tokens(message + next_id, model=\"gpt-4\")\n",
    "\t\t\t> token_budget\n",
    "\t\t):\n",
    "\t\t\tbreak\n",
    "\t\telse:\n",
    "\t\t\tmessage += next_id\n",
    "\treturn message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AnswerDoc(keywords: list | None, query: str):\n",
    "\n",
    "    multiple_answers_output = MultipleAnswers(query)\n",
    "\n",
    "    answers = multiple_answers_output.split(\"====\")\n",
    "\n",
    "    answers = [s for s in answers if s.strip()]\n",
    "\n",
    "    logging.info(f\"answers:\\n {answers}\")\n",
    "\n",
    "    accumulator = pd.DataFrame()\n",
    "    for ans in answers:\n",
    "        ans_embedding = multiple_voyage_query_embedding(ans)\n",
    "        df_top_n = FetchTopN(ans_embedding)\n",
    "        accumulator = pd.concat([accumulator, df_top_n], ignore_index=True)\n",
    "        logging.info(f\"accumulator before:\\n {accumulator}\")\n",
    "    \n",
    "    # Corrected the inplace operation and variable name\n",
    "    accumulator.drop_duplicates(inplace=True)\n",
    "    logging.info(accumulator)\n",
    "\n",
    "    if keywords is not None:\n",
    "        accumulator = filter_keywords(accumulator, keywords)\n",
    "    \n",
    "    formatted_message = FormatTopN(accumulator)\n",
    "    logging.info(formatted_message)\n",
    "\n",
    "    final_ans = FinanceExpert(query, formatted_message)\n",
    "    #logging.info(final_ans)\n",
    "\n",
    "    return final_ans\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = None\n",
    "query = \"How is the company's operations and financial performance affected by the current global economic conditions, such as interest rates, inflation trends, and currency fluctuations?\"\n",
    "\n",
    "response = AnswerDoc(keywords, query)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
